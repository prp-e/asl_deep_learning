{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banner-graphic",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complicated-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "congressional-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "english-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.100270</td>\n",
       "      <td>0.770458</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.171125</td>\n",
       "      <td>0.742621</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>0.631566</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042279</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>0.475311</td>\n",
       "      <td>-0.088015</td>\n",
       "      <td>0.062207</td>\n",
       "      <td>0.548142</td>\n",
       "      <td>-0.096761</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.590701</td>\n",
       "      <td>-0.092907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.115275</td>\n",
       "      <td>0.756047</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.190911</td>\n",
       "      <td>0.693923</td>\n",
       "      <td>-0.015533</td>\n",
       "      <td>0.235935</td>\n",
       "      <td>0.596866</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043746</td>\n",
       "      <td>0.097983</td>\n",
       "      <td>0.420535</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>0.097467</td>\n",
       "      <td>0.477497</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>0.515680</td>\n",
       "      <td>0.051265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.131161</td>\n",
       "      <td>0.733416</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.213521</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>-0.007896</td>\n",
       "      <td>0.256543</td>\n",
       "      <td>0.559400</td>\n",
       "      <td>-0.010642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.116334</td>\n",
       "      <td>0.392015</td>\n",
       "      <td>0.042380</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.123581</td>\n",
       "      <td>0.478869</td>\n",
       "      <td>0.069520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x1        y1        z1        x2        y2        z2        x3  \\\n",
       "0     A  0.100270  0.770458 -0.000005  0.171125  0.742621 -0.049046  0.225460   \n",
       "1     A  0.115275  0.756047 -0.000035  0.190911  0.693923 -0.015533  0.235935   \n",
       "2     A  0.131161  0.733416 -0.000019  0.213521  0.662332 -0.007896  0.256543   \n",
       "\n",
       "         y3        z3  ...       z18       x19       y19       z19       x20  \\\n",
       "0  0.631566 -0.063864  ... -0.042279  0.058964  0.475311 -0.088015  0.062207   \n",
       "1  0.596866 -0.024315  ...  0.043746  0.097983  0.420535  0.030576  0.097467   \n",
       "2  0.559400 -0.010642  ...  0.053936  0.116334  0.392015  0.042380  0.121460   \n",
       "\n",
       "        y20       z20       x21       y21       z21  \n",
       "0  0.548142 -0.096761  0.072088  0.590701 -0.092907  \n",
       "1  0.477497  0.031967  0.094879  0.515680  0.051265  \n",
       "2  0.448187  0.044218  0.123581  0.478869  0.069520  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "governmental-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21130</th>\n",
       "      <td>Nothing</td>\n",
       "      <td>0.376256</td>\n",
       "      <td>0.759999</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.429514</td>\n",
       "      <td>0.727702</td>\n",
       "      <td>-0.015731</td>\n",
       "      <td>0.473136</td>\n",
       "      <td>0.661299</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>0.331783</td>\n",
       "      <td>0.496862</td>\n",
       "      <td>-0.007641</td>\n",
       "      <td>0.327907</td>\n",
       "      <td>0.454280</td>\n",
       "      <td>-0.015026</td>\n",
       "      <td>0.326819</td>\n",
       "      <td>0.416224</td>\n",
       "      <td>-0.021033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131</th>\n",
       "      <td>Nothing</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.429254</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>-0.017213</td>\n",
       "      <td>0.471954</td>\n",
       "      <td>0.662971</td>\n",
       "      <td>-0.021648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>0.330636</td>\n",
       "      <td>0.498538</td>\n",
       "      <td>-0.012001</td>\n",
       "      <td>0.326347</td>\n",
       "      <td>0.456145</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>0.324596</td>\n",
       "      <td>0.417717</td>\n",
       "      <td>-0.025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21132</th>\n",
       "      <td>Nothing</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.762320</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.429105</td>\n",
       "      <td>0.729657</td>\n",
       "      <td>-0.016588</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.663720</td>\n",
       "      <td>-0.020758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010955</td>\n",
       "      <td>0.328639</td>\n",
       "      <td>0.500814</td>\n",
       "      <td>-0.017614</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>0.457881</td>\n",
       "      <td>-0.026502</td>\n",
       "      <td>0.323250</td>\n",
       "      <td>0.420010</td>\n",
       "      <td>-0.033198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class        x1        y1        z1        x2        y2        z2  \\\n",
       "21130  Nothing  0.376256  0.759999 -0.000064  0.429514  0.727702 -0.015731   \n",
       "21131  Nothing  0.377025  0.759245 -0.000063  0.429254  0.727779 -0.017213   \n",
       "21132  Nothing  0.376409  0.762320 -0.000056  0.429105  0.729657 -0.016588   \n",
       "\n",
       "             x3        y3        z3  ...       z18       x19       y19  \\\n",
       "21130  0.473136  0.661299 -0.018908  ... -0.003417  0.331783  0.496862   \n",
       "21131  0.471954  0.662971 -0.021648  ... -0.006872  0.330636  0.498538   \n",
       "21132  0.471300  0.663720 -0.020758  ... -0.010955  0.328639  0.500814   \n",
       "\n",
       "            z19       x20       y20       z20       x21       y21       z21  \n",
       "21130 -0.007641  0.327907  0.454280 -0.015026  0.326819  0.416224 -0.021033  \n",
       "21131 -0.012001  0.326347  0.456145 -0.019459  0.324596  0.417717 -0.025880  \n",
       "21132 -0.017614  0.324583  0.457881 -0.026502  0.323250  0.420010 -0.033198  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worldwide-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beneficial-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100270</td>\n",
       "      <td>0.770458</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.171125</td>\n",
       "      <td>0.742621</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>0.631566</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>0.242905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042279</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>0.475311</td>\n",
       "      <td>-0.088015</td>\n",
       "      <td>0.062207</td>\n",
       "      <td>0.548142</td>\n",
       "      <td>-0.096761</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.590701</td>\n",
       "      <td>-0.092907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.115275</td>\n",
       "      <td>0.756047</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.190911</td>\n",
       "      <td>0.693923</td>\n",
       "      <td>-0.015533</td>\n",
       "      <td>0.235935</td>\n",
       "      <td>0.596866</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>0.259618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043746</td>\n",
       "      <td>0.097983</td>\n",
       "      <td>0.420535</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>0.097467</td>\n",
       "      <td>0.477497</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>0.515680</td>\n",
       "      <td>0.051265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131161</td>\n",
       "      <td>0.733416</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.213521</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>-0.007896</td>\n",
       "      <td>0.256543</td>\n",
       "      <td>0.559400</td>\n",
       "      <td>-0.010642</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.116334</td>\n",
       "      <td>0.392015</td>\n",
       "      <td>0.042380</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.123581</td>\n",
       "      <td>0.478869</td>\n",
       "      <td>0.069520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        y1        z1        x2        y2        z2        x3  \\\n",
       "0  0.100270  0.770458 -0.000005  0.171125  0.742621 -0.049046  0.225460   \n",
       "1  0.115275  0.756047 -0.000035  0.190911  0.693923 -0.015533  0.235935   \n",
       "2  0.131161  0.733416 -0.000019  0.213521  0.662332 -0.007896  0.256543   \n",
       "\n",
       "         y3        z3        x4  ...       z18       x19       y19       z19  \\\n",
       "0  0.631566 -0.063864  0.242905  ... -0.042279  0.058964  0.475311 -0.088015   \n",
       "1  0.596866 -0.024315  0.259618  ...  0.043746  0.097983  0.420535  0.030576   \n",
       "2  0.559400 -0.010642  0.279885  ...  0.053936  0.116334  0.392015  0.042380   \n",
       "\n",
       "        x20       y20       z20       x21       y21       z21  \n",
       "0  0.062207  0.548142 -0.096761  0.072088  0.590701 -0.092907  \n",
       "1  0.097467  0.477497  0.031967  0.094879  0.515680  0.051265  \n",
       "2  0.121460  0.448187  0.044218  0.123581  0.478869  0.069520  \n",
       "\n",
       "[3 rows x 63 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "controlling-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "utility-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "light-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    if i == 'Nothing':\n",
    "        new_y.append(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "novel-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21133"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "genuine-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, new_y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "controversial-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "noble-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "comparative-queen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14793, 1, 63)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "satisfied-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train, (y_train.shape[0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "hidden-agent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14793, 1, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hazardous-percentage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25,  4, 14, ..., 13,  3, 23])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-joseph",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "excited-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "whole-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "logdir = os.path.join('logs')\n",
    "tb_callbacks = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dried-winter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14793, 1, 63)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "X.shape\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "honest-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=X.shape))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(units=1, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "outside-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 21133, 64)         32768     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 21133, 128)        98816     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 181,057\n",
      "Trainable params: 181,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 21133, 63) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21133, 63), dtype=tf.float32, name='lstm_7_input'), name='lstm_7_input', description=\"created by layer 'lstm_7_input'\"), but it was called on an input with incompatible shape (None, 1, 63).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 21133, 63) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21133, 63), dtype=tf.float32, name='lstm_7_input'), name='lstm_7_input', description=\"created by layer 'lstm_7_input'\"), but it was called on an input with incompatible shape (None, 1, 63).\n",
      "463/463 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 2/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 3/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 4/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 5/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 6/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 7/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 8/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 9/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 10/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 11/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 12/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 13/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 14/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 15/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 16/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 17/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 18/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 19/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 20/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 21/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 22/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 23/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 24/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 25/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 26/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 27/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 28/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 29/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 30/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 31/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 32/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 33/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 34/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 35/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 36/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 37/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 38/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 39/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 40/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 41/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 42/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 43/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 44/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 45/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 46/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 47/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 48/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 49/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 50/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 51/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 52/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 53/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 54/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 55/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 56/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 57/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 58/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 59/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 60/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 61/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 62/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 63/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 64/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 65/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 66/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 67/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 68/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 69/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 70/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 72/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 73/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 74/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 75/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 76/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 77/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 78/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 79/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 80/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 81/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 82/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 83/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 84/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 85/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 86/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 87/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 88/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 89/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 90/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 91/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 92/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 93/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 94/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 95/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 96/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 97/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 98/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 99/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 100/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 101/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 102/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 103/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 104/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 105/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 106/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 107/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 108/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 109/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 110/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 111/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 112/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 113/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 114/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 115/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 116/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 117/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 118/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 119/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 120/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 121/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 122/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 123/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 124/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 125/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 126/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 127/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 128/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 129/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 130/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 131/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 132/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 133/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 134/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 135/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 136/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 137/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 138/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 139/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272: 0s - loss: 0.0000e+00 - accuracy: 0.02\n",
      "Epoch 140/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 141/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 142/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 143/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 144/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 145/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 147/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 148/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 149/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 150/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 151/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 152/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 153/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 154/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 155/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 156/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 157/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 158/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 159/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 160/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 161/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 162/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 163/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 164/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 165/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 166/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 167/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 168/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 169/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 170/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 171/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 172/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 173/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 174/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 175/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 176/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 177/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 178/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 179/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 180/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 181/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 182/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 183/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 184/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 185/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 186/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 187/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 188/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 189/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 190/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 191/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 192/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 193/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 194/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 195/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 196/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 197/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 198/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 199/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 200/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 201/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 202/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 203/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 204/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 205/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 206/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 207/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 208/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 209/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 210/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 211/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 212/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 213/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 214/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 215/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 216/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 217/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 218/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 219/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 220/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 221/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 223/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 224/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 225/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 226/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 227/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 228/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 229/2000\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 230/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 231/2000\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 232/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 233/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 234/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 235/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 236/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 237/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 238/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 239/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 240/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 241/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 242/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 243/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 244/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 245/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 246/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 247/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 248/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 249/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 250/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 251/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 252/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 253/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 254/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 255/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 256/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 257/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 258/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 259/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 260/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 261/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 262/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 263/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 264/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 265/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 266/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 267/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 268/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 269/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 270/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 271/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 272/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 273/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 274/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 275/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 276/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 277/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 278/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 279/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 280/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 281/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 282/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 283/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 284/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 285/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 286/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 287/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 288/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 289/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 290/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 291/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 292/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 293/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 294/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 295/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 296/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 297/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 298/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 299/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 300/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 301/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 302/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 303/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 304/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 305/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 306/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 307/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 308/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 309/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 310/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 311/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 312/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 313/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 314/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 315/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 316/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 317/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 318/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 319/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 320/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 321/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 322/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 323/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 324/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 325/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 326/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 327/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 328/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 329/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 330/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 331/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 332/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 333/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 334/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 335/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 336/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 337/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 338/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 339/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 340/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 341/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 342/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 343/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 344/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 345/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 346/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 347/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 348/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 349/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 350/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 351/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 352/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 353/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 354/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 355/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 356/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 357/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 358/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 359/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 360/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 361/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 362/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 363/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 364/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 365/2000\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 366/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 367/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 368/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 369/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 370/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 371/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 372/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 374/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 375/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 376/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 377/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 378/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 379/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 380/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 381/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 382/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 383/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 384/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 385/2000\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0272\n",
      "Epoch 386/2000\n",
      "228/463 [=============>................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.0278"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "informal-atlanta",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 399420 into shape (6340,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-7aaab7113c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 399420 into shape (6340,1,1)"
     ]
    }
   ],
   "source": [
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "heavy-creation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6340, 1, 63)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ancient-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subject = np.reshape(x_test[35], (1, 1, 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "labeled-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "secondary-economics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-leeds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
